{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9bc8289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  date                               chat        sender  \\\n",
      "0  2025-06-24 09:05:42                    ሐዋርያዊ መልሶች Chat          ነፂ 🥀   \n",
      "1  2025-06-24 09:06:48                    ሐዋርያዊ መልሶች Chat     mekutii12   \n",
      "2  2025-06-24 09:07:31  Tulips Event & sales 🤝 Xpand SMMA   TulipsEvent   \n",
      "3  2025-06-24 09:09:08  Tulips Event & sales 🤝 Xpand SMMA   TulipsEvent   \n",
      "4  2025-06-24 09:09:08                    ሐዋርያዊ መልሶች Chat  mklldouble_g   \n",
      "\n",
      "                                             message  \\\n",
      "0  በገነት በነበረች በዕፀ ህይውት ፈንታ  በምድር ተተከለች ልትሆነው ለአዳም...   \n",
      "1  እናት አግኝቼሻለው ከመስቀሉ እግርጌ ስሟን እየጠራሁ ከፍ እንዲል ማዕረጌ ...   \n",
      "2  #NewArrival 😍Ladies Gift Combo 😍  Commission (...   \n",
      "3   🟥Gucci ladies bag light brown color 🟥 Sold out 🟥   \n",
      "4                                     እረፍት አታስዱም እንዴ   \n",
      "\n",
      "                                     cleaned_message  \\\n",
      "0  በገነት በነበረች በዕፀ ህይውት ፈንታ በምድር ተተከለች ልትሆነው ለአዳም ...   \n",
      "1  እናት አግኝቼሻለው ከመስቀሉ እግርጌ ስሟን እየጠራሁ ከፍ እንዲል ማዕረጌ ...   \n",
      "2  newarrival ladies gift combo  commission ኮሚሽን ...   \n",
      "3       gucci ladies bag light brown color  sold out   \n",
      "4                                     እረፍት አታስዱም እንዴ   \n",
      "\n",
      "                                              tokens  \n",
      "0  በገነት በነበረች በዕፀ ህይውት ፈንታ በምድር ተተከለች ልትሆነው ለአዳም ...  \n",
      "1  እናት አግኝቼሻለው ከመስቀሉ እግርጌ ስሟን እየጠራሁ ከፍ እንዲል ማዕረጌ ...  \n",
      "2  newarrival ladies gift combo commission ኮሚሽን 5...  \n",
      "3        gucci ladies bag light brown color sold out  \n",
      "4                                     እረፍት አታስዱም እንዴ  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your cleaned CSV with tokenized messages\n",
    "df = pd.read_csv(\"data/messages.csv\", encoding=\"utf-8\")\n",
    "\n",
    "print(df.head())  # Inspect first rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "193e5e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             message  \\\n",
      "0  በገነት በነበረች በዕፀ ህይውት ፈንታ  በምድር ተተከለች ልትሆነው ለአዳም...   \n",
      "1  እናት አግኝቼሻለው ከመስቀሉ እግርጌ ስሟን እየጠራሁ ከፍ እንዲል ማዕረጌ ...   \n",
      "2  #NewArrival 😍Ladies Gift Combo 😍  Commission (...   \n",
      "3   🟥Gucci ladies bag light brown color 🟥 Sold out 🟥   \n",
      "4                                     እረፍት አታስዱም እንዴ   \n",
      "\n",
      "                                     cleaned_message  \\\n",
      "0  በገነት በነበረች በዕፀ ህይውት ፈንታ  በምድር ተተከለች ልትሆነው ለአዳም...   \n",
      "1  እናት አግኝቼሻለው ከመስቀሉ እግርጌ ስሟን እየጠራሁ ከፍ እንዲል ማዕረጌ ...   \n",
      "2  newarrival ladies gift combo   commission ኮሚሽን...   \n",
      "3      gucci ladies bag light brown color  sold out    \n",
      "4                                     እረፍት አታስዱም እንዴ   \n",
      "\n",
      "                                              tokens  \n",
      "0  [በገነት, በነበረች, በዕፀ, ህይውት, ፈንታ, በምድር, ተተከለች, ልትሆ...  \n",
      "1  [እናት, አግኝቼሻለው, ከመስቀሉ, እግርጌ, ስሟን, እየጠራሁ, ከፍ, እን...  \n",
      "2  [newarrival, ladies, gift, combo, commission, ...  \n",
      "3  [gucci, ladies, bag, light, brown, color, sold...  \n",
      "4                                 [እረፍት, አታስዱም, እንዴ]  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Lowercase (if applicable) & remove unwanted characters\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "# Example: preprocess and tokenize a column\n",
    "df['cleaned_message'] = df['message'].apply(clean_text)\n",
    "df['tokens'] = df['cleaned_message'].apply(tokenize)\n",
    "\n",
    "print(df[['message', 'cleaned_message', 'tokens']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76c68638",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/ner_raw.conll\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for tokens in df[\"tokens\"]:\n",
    "        for token in tokens:\n",
    "            f.write(f\"{token} O\\n\")\n",
    "        f.write(\"\\n\")  # Blank line between messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac19f1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated data saved to data/ner_annotated.conll\n"
     ]
    }
   ],
   "source": [
    "# Example annotated data format:\n",
    "# A list of sentences, each sentence is a list of (token, label) tuples\n",
    "annotated_data = [\n",
    "    [(\"አፍሪካ\", \"B-ORG\"), (\"ሓየተየግማህበር\", \"I-ORG\"), (\"ማብቅያ\", \"O\"), (\"ቀን\", \"O\")],\n",
    "    [(\"አዳማ\", \"B-LOC\"), (\"ከተማ\", \"I-LOC\")],\n",
    "    [(\"ቴስፋ\", \"B-PER\"), (\"ባች\", \"I-PER\")]\n",
    "]\n",
    "\n",
    "output_path = \"data/ner_annotated.conll\"\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for sentence in annotated_data:\n",
    "        for token, label in sentence:\n",
    "            f.write(f\"{token} {label}\\n\")\n",
    "        f.write(\"\\n\")  # Blank line to separate sentences\n",
    "\n",
    "print(f\"Annotated data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "068a2184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted CoNLL to spaCy format\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "def read_conll(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.read().strip().split(\"\\n\\n\")\n",
    "    data = []\n",
    "    for block in lines:\n",
    "        tokens = []\n",
    "        tags = []\n",
    "        for line in block.split(\"\\n\"):\n",
    "            token, tag = line.split()\n",
    "            tokens.append(token)\n",
    "            tags.append(tag)\n",
    "        data.append((tokens, tags))\n",
    "    return data\n",
    "\n",
    "def conll_to_spacy(data, nlp):\n",
    "    doc_bin = DocBin()\n",
    "    for tokens, tags in data:\n",
    "        doc = spacy.tokens.Doc(nlp.vocab, words=tokens)\n",
    "        ents = []\n",
    "        start = None\n",
    "        end = None\n",
    "        label = None\n",
    "        for i, tag in enumerate(tags):\n",
    "            if tag.startswith(\"B-\"):\n",
    "                if start is not None:\n",
    "                    ents.append(spacy.tokens.Span(doc, start, end, label=label))\n",
    "                start = i\n",
    "                end = i + 1\n",
    "                label = tag[2:]\n",
    "            elif tag.startswith(\"I-\") and start is not None:\n",
    "                end = i + 1\n",
    "            else:\n",
    "                if start is not None:\n",
    "                    ents.append(spacy.tokens.Span(doc, start, end, label=label))\n",
    "                    start = None\n",
    "                    end = None\n",
    "                    label = None\n",
    "        # catch last entity\n",
    "        if start is not None:\n",
    "            ents.append(spacy.tokens.Span(doc, start, end, label=label))\n",
    "        doc.ents = ents\n",
    "        doc_bin.add(doc)\n",
    "    return doc_bin\n",
    "\n",
    "nlp = spacy.blank(\"am\")  # Assuming Amharic language model, or replace with \"en\" if English\n",
    "data = read_conll(\"data/ner_annotated.conll\")\n",
    "doc_bin = conll_to_spacy(data, nlp)\n",
    "doc_bin.to_disk(\"data/train.spacy\")\n",
    "print(\"Converted CoNLL to spaCy format\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
